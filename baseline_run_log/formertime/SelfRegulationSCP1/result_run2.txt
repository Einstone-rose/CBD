[[142.   5.]
 [ 44. 102.]]
step4
{'acc': 0.8327645051194539, 'f1': 0.8063241106719368, 'precision': 0.9532710280373832, 'recall': 0.6986301369863014, 'test_loss': 0.4171967387199402}
saving model of step4
Model train epoch:1,loss:1.872933852672577,training_time:0.6852472797036171
[[  0. 147.]
 [  0. 146.]]
step8
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.6826823353767395}
Model train epoch:2,loss:0.6906361937522888,training_time:0.5503623932600021
[[  0. 147.]
 [  0. 146.]]
step12
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.6620415687561035}
Model train epoch:3,loss:0.7194977164268493,training_time:0.5273788198828697
[[140.   7.]
 [ 34. 112.]]
step16
{'acc': 0.8600682593856656, 'f1': 0.8452830188679246, 'precision': 0.9411764705882353, 'recall': 0.7671232876712328, 'test_loss': 0.38813974261283873}
saving model of step16
[[120.  27.]
 [ 16. 130.]]
step20
{'acc': 0.8532423208191127, 'f1': 0.858085808580858, 'precision': 0.8280254777070064, 'recall': 0.8904109589041096, 'test_loss': 0.4986889362335205}
Model train epoch:4,loss:0.6898531913757324,training_time:0.6815136820077896
[[  0. 147.]
 [  0. 146.]]
step24
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.5338068425655365}
Model train epoch:5,loss:0.6343314290046692,training_time:0.5287526696920395
[[124.  23.]
 [ 18. 128.]]
step28
{'acc': 0.8600682593856656, 'f1': 0.861952861952862, 'precision': 0.847682119205298, 'recall': 0.8767123287671232, 'test_loss': 0.4363094687461853}
saving model of step28
Model train epoch:6,loss:0.5880626082420349,training_time:0.5849608704447746
[[129.  18.]
 [ 23. 123.]]
step32
{'acc': 0.8600682593856656, 'f1': 0.8571428571428571, 'precision': 0.8723404255319149, 'recall': 0.8424657534246576, 'test_loss': 0.3747743904590607}
saving model of step32
Model train epoch:7,loss:0.6521838068962097,training_time:0.5825855955481529
[[106.  41.]
 [ 12. 134.]]
step36
{'acc': 0.8191126279863481, 'f1': 0.8348909657320872, 'precision': 0.7657142857142857, 'recall': 0.9178082191780822, 'test_loss': 0.4569213569164276}
[[ 94.  53.]
 [ 11. 135.]]
step40
{'acc': 0.7815699658703071, 'f1': 0.8083832335329343, 'precision': 0.7180851063829787, 'recall': 0.9246575342465754, 'test_loss': 0.5225041508674622}
Model train epoch:8,loss:0.588940703868866,training_time:0.6422249227762222
[[100.  47.]
 [ 12. 134.]]
step44
{'acc': 0.7986348122866894, 'f1': 0.819571865443425, 'precision': 0.7403314917127072, 'recall': 0.9178082191780822, 'test_loss': 0.46631133556365967}
Model train epoch:9,loss:0.5861069679260253,training_time:0.542710930109024
[[100.  47.]
 [ 11. 135.]]
step48
{'acc': 0.8020477815699659, 'f1': 0.8231707317073171, 'precision': 0.7417582417582418, 'recall': 0.9246575342465754, 'test_loss': 0.4900816082954407}
Model train epoch:10,loss:0.5631996393203735,training_time:0.5503112152218819
[[  0. 147.]
 [  0. 146.]]
step52
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.6563874363899231}
Model train epoch:11,loss:0.5627506494522094,training_time:0.5491136163473129
[[ 98.  49.]
 [ 11. 135.]]
step56
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.5046030879020691}
[[ 98.  49.]
 [ 11. 135.]]
step60
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.5135580420494079}
Model train epoch:12,loss:0.5991841793060303,training_time:0.6662712320685387
[[  0. 147.]
 [  0. 146.]]
step64
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.6962431192398071}
Model train epoch:13,loss:0.6117959380149841,training_time:0.5490404441952705
[[ 99.  48.]
 [ 11. 135.]]
step68
{'acc': 0.7986348122866894, 'f1': 0.8206686930091186, 'precision': 0.7377049180327869, 'recall': 0.9246575342465754, 'test_loss': 0.49903721213340757}
Model train epoch:14,loss:0.5385518252849579,training_time:0.5684986338019371
[[102.  45.]
 [ 12. 134.]]
step72
{'acc': 0.8054607508532423, 'f1': 0.8246153846153845, 'precision': 0.7486033519553073, 'recall': 0.9178082191780822, 'test_loss': 0.4384604811668396}
Model train epoch:15,loss:0.5607322156429291,training_time:0.5496866405010223
[[ 98.  49.]
 [ 11. 135.]]
step76
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.5088261842727662}
[[ 92.  55.]
 [ 11. 135.]]
step80
{'acc': 0.7747440273037542, 'f1': 0.8035714285714286, 'precision': 0.7105263157894737, 'recall': 0.9246575342465754, 'test_loss': 0.5834078907966613}
Model train epoch:16,loss:0.548522436618805,training_time:0.655081570148468
[[ 92.  55.]
 [ 11. 135.]]
step84
{'acc': 0.7747440273037542, 'f1': 0.8035714285714286, 'precision': 0.7105263157894737, 'recall': 0.9246575342465754, 'test_loss': 0.5597443521022797}
Model train epoch:17,loss:0.5756830334663391,training_time:0.5522856041789055
[[ 96.  51.]
 [ 11. 135.]]
step88
{'acc': 0.78839590443686, 'f1': 0.8132530120481927, 'precision': 0.7258064516129032, 'recall': 0.9246575342465754, 'test_loss': 0.5053299188613891}
Model train epoch:18,loss:0.5233307838439941,training_time:0.5419756546616554
[[ 98.  49.]
 [ 11. 135.]]
step92
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.48977941274642944}
Model train epoch:19,loss:0.5292145907878876,training_time:0.5505270734429359
[[ 92.  55.]
 [ 11. 135.]]
step96
{'acc': 0.7747440273037542, 'f1': 0.8035714285714286, 'precision': 0.7105263157894737, 'recall': 0.9246575342465754, 'test_loss': 0.5877233147621155}
[[ 92.  55.]
 [ 11. 135.]]
step100
{'acc': 0.7747440273037542, 'f1': 0.8035714285714286, 'precision': 0.7105263157894737, 'recall': 0.9246575342465754, 'test_loss': 0.6309763550758362}
Model train epoch:20,loss:0.5207069039344787,training_time:0.6449635550379753
[[ 99.  48.]
 [ 11. 135.]]
step104
{'acc': 0.7986348122866894, 'f1': 0.8206686930091186, 'precision': 0.7377049180327869, 'recall': 0.9246575342465754, 'test_loss': 0.5260044753551483}
Model train epoch:21,loss:0.5485922694206238,training_time:0.5556062608957291
[[ 97.  50.]
 [ 11. 135.]]
step108
{'acc': 0.7918088737201365, 'f1': 0.8157099697885196, 'precision': 0.7297297297297297, 'recall': 0.9246575342465754, 'test_loss': 0.5465643167495727}
Model train epoch:22,loss:0.5246549606323242,training_time:0.537926010787487
[[ 92.  55.]
 [ 11. 135.]]
step112
{'acc': 0.7747440273037542, 'f1': 0.8035714285714286, 'precision': 0.7105263157894737, 'recall': 0.9246575342465754, 'test_loss': 0.6490488886833191}
Model train epoch:23,loss:0.5317574262619018,training_time:0.5990621224045753
[[ 98.  49.]
 [ 11. 135.]]
step116
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.5415238976478577}
[[ 98.  49.]
 [ 11. 135.]]
step120
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.5042846620082855}
Model train epoch:24,loss:0.5038210809230804,training_time:0.6915304809808731
[[ 85.  62.]
 [  7. 139.]]
step124
{'acc': 0.764505119453925, 'f1': 0.8011527377521614, 'precision': 0.6915422885572139, 'recall': 0.952054794520548, 'test_loss': 0.6697158217430115}
Model train epoch:25,loss:0.5289753377437592,training_time:0.5550920143723488
[[ 97.  50.]
 [ 10. 136.]]
step128
{'acc': 0.7952218430034129, 'f1': 0.8192771084337349, 'precision': 0.7311827956989247, 'recall': 0.9315068493150684, 'test_loss': 0.5250309765338897}
Model train epoch:26,loss:0.5120707154273987,training_time:0.5489055141806602
[[102.  45.]
 [ 12. 134.]]
step132
{'acc': 0.8054607508532423, 'f1': 0.8246153846153845, 'precision': 0.7486033519553073, 'recall': 0.9178082191780822, 'test_loss': 0.45975173115730283}
Model train epoch:27,loss:0.5124294996261597,training_time:0.5309155210852623
[[ 93.  54.]
 [ 12. 134.]]
step136
{'acc': 0.7747440273037542, 'f1': 0.8023952095808382, 'precision': 0.7127659574468085, 'recall': 0.9178082191780822, 'test_loss': 0.5875570058822632}
[[ 94.  53.]
 [ 10. 136.]]
step140
{'acc': 0.7849829351535836, 'f1': 0.8119402985074626, 'precision': 0.7195767195767195, 'recall': 0.9315068493150684, 'test_loss': 0.5934424877166748}
Model train epoch:28,loss:0.5287470817565918,training_time:0.6422790437936783
[[ 98.  49.]
 [ 11. 135.]]
step144
{'acc': 0.7952218430034129, 'f1': 0.8181818181818183, 'precision': 0.7336956521739131, 'recall': 0.9246575342465754, 'test_loss': 0.4779913067817688}
Model train epoch:29,loss:0.4805148899555206,training_time:0.5397813469171524
[[ 91.  56.]
 [  9. 137.]]
step148
{'acc': 0.7781569965870307, 'f1': 0.8082595870206489, 'precision': 0.7098445595854922, 'recall': 0.9383561643835616, 'test_loss': 0.5523841321468353}
Model train epoch:30,loss:0.4530267477035522,training_time:0.5237942412495613
[[ 78.  69.]
 [  6. 140.]]
step152
{'acc': 0.7440273037542662, 'f1': 0.7887323943661971, 'precision': 0.6698564593301436, 'recall': 0.958904109589041, 'test_loss': 0.6616916418075561}
Model train epoch:31,loss:0.4232377529144287,training_time:0.5217006877064705
[[102.  45.]
 [ 10. 136.]]
step156
{'acc': 0.8122866894197952, 'f1': 0.8318042813455657, 'precision': 0.7513812154696132, 'recall': 0.9315068493150684, 'test_loss': 0.6649626731872559}
[[118.  29.]
 [ 15. 131.]]
step160
{'acc': 0.8498293515358362, 'f1': 0.8562091503267975, 'precision': 0.81875, 'recall': 0.8972602739726028, 'test_loss': 0.46408575773239136}
Model train epoch:32,loss:0.4113445281982422,training_time:0.6213125586509705
[[109.  38.]
 [ 12. 134.]]
step164
{'acc': 0.8293515358361775, 'f1': 0.8427672955974842, 'precision': 0.7790697674418605, 'recall': 0.9178082191780822, 'test_loss': 0.5774164378643036}
Model train epoch:33,loss:0.425169962644577,training_time:0.5549322590231895
[[ 89.  58.]
 [  8. 138.]]
step168
{'acc': 0.7747440273037542, 'f1': 0.8070175438596492, 'precision': 0.7040816326530612, 'recall': 0.9452054794520548, 'test_loss': 0.6508657455444335}
Model train epoch:34,loss:0.34874364733695984,training_time:0.557699166238308
[[ 81.  66.]
 [  8. 138.]]
step172
{'acc': 0.7474402730375427, 'f1': 0.7885714285714286, 'precision': 0.6764705882352942, 'recall': 0.9452054794520548, 'test_loss': 0.7234810829162598}
Model train epoch:35,loss:0.4076788127422333,training_time:0.5231049880385399
[[ 97.  50.]
 [  9. 137.]]
step176
{'acc': 0.7986348122866894, 'f1': 0.8228228228228228, 'precision': 0.732620320855615, 'recall': 0.9383561643835616, 'test_loss': 0.6108500123023987}
[[108.  39.]
 [ 10. 136.]]
step180
{'acc': 0.8327645051194539, 'f1': 0.8473520249221184, 'precision': 0.7771428571428571, 'recall': 0.9315068493150684, 'test_loss': 0.48657108545303346}
Model train epoch:36,loss:0.492581307888031,training_time:0.6169161051511765
[[101.  46.]
 [  9. 137.]]
step184
{'acc': 0.8122866894197952, 'f1': 0.8328267477203647, 'precision': 0.7486338797814208, 'recall': 0.9383561643835616, 'test_loss': 0.5433534920215607}
Model train epoch:37,loss:0.3673929512500763,training_time:0.5296478271484375
[[ 65.  82.]
 [ 10. 136.]]
step188
{'acc': 0.6860068259385665, 'f1': 0.7472527472527473, 'precision': 0.6238532110091743, 'recall': 0.9315068493150684, 'test_loss': 0.946552062034607}
Model train epoch:38,loss:0.4171148121356964,training_time:0.5231056287884712
[[113.  34.]
 [ 17. 129.]]
step192
{'acc': 0.825938566552901, 'f1': 0.8349514563106796, 'precision': 0.7914110429447853, 'recall': 0.8835616438356164, 'test_loss': 0.5403736054897308}
Model train epoch:39,loss:0.2930895656347275,training_time:0.5220169425010681
[[ 96.  51.]
 [ 20. 126.]]
step196
{'acc': 0.757679180887372, 'f1': 0.7801857585139319, 'precision': 0.711864406779661, 'recall': 0.863013698630137, 'test_loss': 0.6313396573066712}
[[ 27. 120.]
 [ 32. 114.]]
step200
{'acc': 0.4812286689419795, 'f1': 0.6, 'precision': 0.48717948717948717, 'recall': 0.7808219178082192, 'test_loss': 1.9719791173934937}
Model train epoch:40,loss:0.32374011278152465,training_time:0.6160261929035187
[[103.  44.]
 [ 17. 129.]]
step204
{'acc': 0.7918088737201365, 'f1': 0.8087774294670845, 'precision': 0.7456647398843931, 'recall': 0.8835616438356164, 'test_loss': 0.5813532829284668}
Model train epoch:41,loss:0.36133809089660646,training_time:0.5215853080153465
[[ 99.  48.]
 [ 15. 131.]]
step208
{'acc': 0.7849829351535836, 'f1': 0.806153846153846, 'precision': 0.7318435754189944, 'recall': 0.8972602739726028, 'test_loss': 0.7153385519981384}
Model train epoch:42,loss:0.25879319608211515,training_time:0.5228626504540443
[[ 75.  72.]
 [ 19. 127.]]
step212
{'acc': 0.689419795221843, 'f1': 0.7362318840579711, 'precision': 0.6381909547738693, 'recall': 0.8698630136986302, 'test_loss': 1.1164849281311036}
Model train epoch:43,loss:0.18259461969137192,training_time:0.5299248173832893
[[ 82.  65.]
 [ 10. 136.]]
step216
{'acc': 0.7440273037542662, 'f1': 0.7838616714697406, 'precision': 0.6766169154228856, 'recall': 0.9315068493150684, 'test_loss': 0.9286379456520081}
[[ 91.  56.]
 [  9. 137.]]
step220
{'acc': 0.7781569965870307, 'f1': 0.8082595870206489, 'precision': 0.7098445595854922, 'recall': 0.9383561643835616, 'test_loss': 0.9200952291488648}
Model train epoch:44,loss:0.13660414814949035,training_time:0.6236785277724266
[[ 79.  68.]
 [  7. 139.]]
step224
{'acc': 0.7440273037542662, 'f1': 0.7875354107648727, 'precision': 0.6714975845410628, 'recall': 0.952054794520548, 'test_loss': 1.197204351425171}
Model train epoch:45,loss:0.12031970210373402,training_time:0.5219511315226555
[[ 65.  82.]
 [  8. 138.]]
step228
{'acc': 0.6928327645051194, 'f1': 0.7540983606557379, 'precision': 0.6272727272727273, 'recall': 0.9452054794520548, 'test_loss': 1.4515453100204467}
Model train epoch:46,loss:0.14639902375638486,training_time:0.5153940096497536
[[103.  44.]
 [ 12. 134.]]
step232
{'acc': 0.8088737201365188, 'f1': 0.8271604938271604, 'precision': 0.7528089887640449, 'recall': 0.9178082191780822, 'test_loss': 1.0335445642471313}
Model train epoch:47,loss:0.027019978361204268,training_time:0.5136557370424271
[[ 95.  52.]
 [ 14. 132.]]
step236
{'acc': 0.7747440273037542, 'f1': 0.8, 'precision': 0.717391304347826, 'recall': 0.9041095890410958, 'test_loss': 1.1533435940742494}
[[ 57.  90.]
 [ 15. 131.]]
step240
{'acc': 0.6416382252559727, 'f1': 0.7138964577656677, 'precision': 0.5927601809954751, 'recall': 0.8972602739726028, 'test_loss': 1.83696711063385}
Model train epoch:48,loss:0.06435592509806157,training_time:0.6300590857863426
[[115.  32.]
 [ 15. 131.]]
step244
{'acc': 0.8395904436860068, 'f1': 0.8478964401294498, 'precision': 0.803680981595092, 'recall': 0.8972602739726028, 'test_loss': 0.9019775390625}
Model train epoch:49,loss:0.10070203803479671,training_time:0.5291313976049423
[[ 78.  69.]
 [ 10. 136.]]
step248
{'acc': 0.7303754266211604, 'f1': 0.7749287749287749, 'precision': 0.6634146341463415, 'recall': 0.9315068493150684, 'test_loss': 1.332635521888733}
Model train epoch:50,loss:0.02931600280571729,training_time:0.5226991325616837
[[ 74.  73.]
 [  8. 138.]]
step252
{'acc': 0.7235494880546075, 'f1': 0.7731092436974789, 'precision': 0.6540284360189573, 'recall': 0.9452054794520548, 'test_loss': 1.4912480115890503}
Model train epoch:51,loss:0.09246544018387795,training_time:0.531020276248455
[[ 54.  93.]
 [ 10. 136.]]
step256
{'acc': 0.6484641638225256, 'f1': 0.7253333333333334, 'precision': 0.5938864628820961, 'recall': 0.9315068493150684, 'test_loss': 2.141874885559082}
[[ 99.  48.]
 [ 13. 133.]]
step260
{'acc': 0.7918088737201365, 'f1': 0.8134556574923547, 'precision': 0.7348066298342542, 'recall': 0.910958904109589, 'test_loss': 1.2503886938095092}
Model train epoch:52,loss:0.034063249453902246,training_time:0.6376915648579597
[[ 55.  92.]
 [ 14. 132.]]
step264
{'acc': 0.6382252559726962, 'f1': 0.7135135135135134, 'precision': 0.5892857142857143, 'recall': 0.9041095890410958, 'test_loss': 2.141221785545349}
Model train epoch:53,loss:0.06814428651705384,training_time:0.5454762130975723
[[ 87.  60.]
 [ 12. 134.]]
step268
{'acc': 0.7542662116040956, 'f1': 0.7882352941176471, 'precision': 0.6907216494845361, 'recall': 0.9178082191780822, 'test_loss': 1.2883175373077393}
Model train epoch:54,loss:0.0775833085179329,training_time:0.5217777416110039
[[ 75.  72.]
 [ 10. 136.]]
step272
{'acc': 0.7201365187713311, 'f1': 0.7683615819209039, 'precision': 0.6538461538461539, 'recall': 0.9315068493150684, 'test_loss': 1.3826202988624572}
Model train epoch:55,loss:0.03975637387484312,training_time:0.5187858417630196
[[ 90.  57.]
 [ 10. 136.]]
step276
{'acc': 0.7713310580204779, 'f1': 0.8023598820058996, 'precision': 0.7046632124352331, 'recall': 0.9315068493150684, 'test_loss': 1.097023856639862}
[[ 76.  71.]
 [  9. 137.]]
step280
{'acc': 0.726962457337884, 'f1': 0.7740112994350282, 'precision': 0.6586538461538461, 'recall': 0.9383561643835616, 'test_loss': 1.3177518725395203}
Model train epoch:56,loss:0.009961613081395626,training_time:0.6200776919722557
[[ 85.  62.]
 [  8. 138.]]
step284
{'acc': 0.7610921501706485, 'f1': 0.7976878612716762, 'precision': 0.69, 'recall': 0.9452054794520548, 'test_loss': 1.3072513937950134}
Model train epoch:57,loss:0.0108535697334446,training_time:0.5338523536920547
[[ 65.  82.]
 [  4. 142.]]
step288
{'acc': 0.7064846416382252, 'f1': 0.7675675675675675, 'precision': 0.6339285714285714, 'recall': 0.9726027397260274, 'test_loss': 1.7637613534927368}
Model train epoch:58,loss:0.013892478798516095,training_time:0.5286151617765427
[[ 64.  83.]
 [  6. 140.]]
step292
{'acc': 0.6962457337883959, 'f1': 0.7588075880758809, 'precision': 0.6278026905829597, 'recall': 0.958904109589041, 'test_loss': 1.83381826877594}
Model train epoch:59,loss:0.0017713873239699751,training_time:0.5123239681124687
[[ 74.  73.]
 [  6. 140.]]
step296
{'acc': 0.7303754266211604, 'f1': 0.7799442896935933, 'precision': 0.6572769953051644, 'recall': 0.958904109589041, 'test_loss': 1.7359063386917115}
[[ 64.  83.]
 [  6. 140.]]
step300
{'acc': 0.6962457337883959, 'f1': 0.7588075880758809, 'precision': 0.6278026905829597, 'recall': 0.958904109589041, 'test_loss': 2.1221845388412475}
Model train epoch:60,loss:0.0014312247221823782,training_time:0.6153878346085548
[[ 59.  88.]
 [  7. 139.]]
step304
{'acc': 0.6757679180887372, 'f1': 0.7453083109919572, 'precision': 0.6123348017621145, 'recall': 0.952054794520548, 'test_loss': 2.295063591003418}
Model train epoch:61,loss:0.0011531340154760984,training_time:0.5675406381487846
[[ 82.  65.]
 [  9. 137.]]
step308
{'acc': 0.7474402730375427, 'f1': 0.7873563218390804, 'precision': 0.6782178217821783, 'recall': 0.9383561643835616, 'test_loss': 1.807387351989746}
Model train epoch:62,loss:0.03442919773515314,training_time:0.5274675115942955
[[ 63.  84.]
 [  9. 137.]]
step312
{'acc': 0.6825938566552902, 'f1': 0.7465940054495913, 'precision': 0.6199095022624435, 'recall': 0.9383561643835616, 'test_loss': 2.086884093284607}
Model train epoch:63,loss:0.21687133850064128,training_time:0.5226970613002777
[[102.  45.]
 [  9. 137.]]
step316
{'acc': 0.8156996587030717, 'f1': 0.8353658536585366, 'precision': 0.7527472527472527, 'recall': 0.9383561643835616, 'test_loss': 1.1199494123458862}
[[ 70.  77.]
 [  8. 138.]]
step320
{'acc': 0.7098976109215017, 'f1': 0.7645429362880887, 'precision': 0.641860465116279, 'recall': 0.9452054794520548, 'test_loss': 1.3878845691680908}
Model train epoch:64,loss:0.052847749495413154,training_time:0.6238097846508026
[[ 76.  71.]
 [ 12. 134.]]
step324
{'acc': 0.7167235494880546, 'f1': 0.7635327635327634, 'precision': 0.6536585365853659, 'recall': 0.9178082191780822, 'test_loss': 1.2357661366462707}
Model train epoch:65,loss:0.019847033510450272,training_time:0.532073974609375
[[ 76.  71.]
 [  8. 138.]]
step328
{'acc': 0.7303754266211604, 'f1': 0.7774647887323944, 'precision': 0.6602870813397129, 'recall': 0.9452054794520548, 'test_loss': 1.325700569152832}
Model train epoch:66,loss:0.0226546342484653,training_time:0.5230997279286385
[[ 70.  77.]
 [  7. 139.]]
step332
{'acc': 0.7133105802047781, 'f1': 0.7679558011049723, 'precision': 0.6435185185185185, 'recall': 0.952054794520548, 'test_loss': 1.522144615650177}
Model train epoch:67,loss:0.007473637955263257,training_time:0.5273377671837807
[[102.  45.]
 [  9. 137.]]
step336
{'acc': 0.8156996587030717, 'f1': 0.8353658536585366, 'precision': 0.7527472527472527, 'recall': 0.9383561643835616, 'test_loss': 0.9355140686035156}
[[ 72.  75.]
 [  7. 139.]]
step340
{'acc': 0.7201365187713311, 'f1': 0.7722222222222223, 'precision': 0.6495327102803738, 'recall': 0.952054794520548, 'test_loss': 1.542821180820465}
Model train epoch:68,loss:0.010879442747682332,training_time:0.6229225769639015
[[ 82.  65.]
 [  8. 138.]]
step344
{'acc': 0.7508532423208191, 'f1': 0.7908309455587392, 'precision': 0.6798029556650246, 'recall': 0.9452054794520548, 'test_loss': 1.4943309783935548}
Model train epoch:69,loss:0.003867630148306489,training_time:0.5340322405099869
[[ 96.  51.]
 [ 10. 136.]]
step348
{'acc': 0.7918088737201365, 'f1': 0.8168168168168167, 'precision': 0.7272727272727273, 'recall': 0.9315068493150684, 'test_loss': 1.282958161830902}
Model train epoch:70,loss:0.00030134420521790164,training_time:0.5225430652499199
[[107.  40.]
 [ 11. 135.]]
step352
{'acc': 0.825938566552901, 'f1': 0.8411214953271028, 'precision': 0.7714285714285715, 'recall': 0.9246575342465754, 'test_loss': 1.1919947862625122}
Model train epoch:71,loss:0.0003144372603856027,training_time:0.5298047289252281
[[104.  43.]
 [ 13. 133.]]
step356
{'acc': 0.8088737201365188, 'f1': 0.8260869565217391, 'precision': 0.7556818181818182, 'recall': 0.910958904109589, 'test_loss': 1.2656606197357179}
[[102.  45.]
 [ 13. 133.]]
step360
{'acc': 0.8020477815699659, 'f1': 0.8209876543209876, 'precision': 0.7471910112359551, 'recall': 0.910958904109589, 'test_loss': 1.368233561515808}
Model train epoch:72,loss:0.0001677647538599558,training_time:0.6215738132596016
[[ 98.  49.]
 [ 13. 133.]]
step364
{'acc': 0.78839590443686, 'f1': 0.8109756097560975, 'precision': 0.7307692307692307, 'recall': 0.910958904109589, 'test_loss': 1.455170464515686}
Model train epoch:73,loss:0.0001184278356959112,training_time:0.5221275240182877
[[ 95.  52.]
 [ 13. 133.]]
step368
{'acc': 0.7781569965870307, 'f1': 0.8036253776435045, 'precision': 0.7189189189189189, 'recall': 0.910958904109589, 'test_loss': 1.527580189704895}
Model train epoch:74,loss:7.709372293902561e-05,training_time:0.5140782371163368
[[ 92.  55.]
 [ 13. 133.]]
step372
{'acc': 0.7679180887372014, 'f1': 0.7964071856287425, 'precision': 0.7074468085106383, 'recall': 0.910958904109589, 'test_loss': 1.5809682607650757}
Model train epoch:75,loss:7.246843742905184e-05,training_time:0.5117333009839058
[[ 90.  57.]
 [ 12. 134.]]
step376
{'acc': 0.764505119453925, 'f1': 0.7952522255192878, 'precision': 0.7015706806282722, 'recall': 0.9178082191780822, 'test_loss': 1.6225330829620361}
[[ 90.  57.]
 [ 12. 134.]]
step380
{'acc': 0.764505119453925, 'f1': 0.7952522255192878, 'precision': 0.7015706806282722, 'recall': 0.9178082191780822, 'test_loss': 1.6543493747711182}
Model train epoch:76,loss:7.126814525690862e-05,training_time:0.6099196672439575
[[ 90.  57.]
 [ 12. 134.]]
step384
{'acc': 0.764505119453925, 'f1': 0.7952522255192878, 'precision': 0.7015706806282722, 'recall': 0.9178082191780822, 'test_loss': 1.677329921722412}
Model train epoch:77,loss:6.238321730052121e-05,training_time:0.5270572751760483
[[ 90.  57.]
 [ 12. 134.]]
step388
{'acc': 0.764505119453925, 'f1': 0.7952522255192878, 'precision': 0.7015706806282722, 'recall': 0.9178082191780822, 'test_loss': 1.692769742012024}
Model train epoch:78,loss:6.453114183386788e-05,training_time:0.524950735270977
[[ 89.  58.]
 [ 12. 134.]]
step392
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.701162052154541}
Model train epoch:79,loss:6.623565641348251e-05,training_time:0.5235535576939583
[[ 89.  58.]
 [ 12. 134.]]
step396
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7059718132019044}
[[ 89.  58.]
 [ 12. 134.]]
step400
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.709852933883667}
Model train epoch:80,loss:5.927676684223115e-05,training_time:0.6241264790296555
[[ 89.  58.]
 [ 12. 134.]]
step404
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7128825664520264}
Model train epoch:81,loss:5.845109626534395e-05,training_time:0.5360347926616669
[[ 89.  58.]
 [ 12. 134.]]
step408
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.715260124206543}
Model train epoch:82,loss:5.5433373199775814e-05,training_time:0.5357564017176628
[[ 89.  58.]
 [ 12. 134.]]
step412
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7174813508987428}
Model train epoch:83,loss:5.6336085981456564e-05,training_time:0.5311350077390671
[[ 89.  58.]
 [ 12. 134.]]
step416
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7192481756210327}
[[ 89.  58.]
 [ 12. 134.]]
step420
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7212029933929442}
Model train epoch:84,loss:5.2466453053057196e-05,training_time:0.6299730464816093
[[ 89.  58.]
 [ 12. 134.]]
step424
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7227949380874634}
Model train epoch:85,loss:5.7771883439272643e-05,training_time:0.5424388721585274
[[ 89.  58.]
 [ 12. 134.]]
step428
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7283532619476318}
Model train epoch:86,loss:5.1829709263984114e-05,training_time:0.5254743918776512
[[ 89.  58.]
 [ 12. 134.]]
step432
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7327412366867065}
Model train epoch:87,loss:5.12464321218431e-05,training_time:0.5226238071918488
[[ 89.  58.]
 [ 12. 134.]]
step436
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7361161708831787}
[[ 89.  58.]
 [ 12. 134.]]
step440
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7390504598617553}
Model train epoch:88,loss:5.070973711553961e-05,training_time:0.6263715699315071
[[ 89.  58.]
 [ 12. 134.]]
step444
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7415005922317506}
Model train epoch:89,loss:4.9964395293500276e-05,training_time:0.526459090411663
[[ 89.  58.]
 [ 12. 134.]]
step448
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7435330390930175}
Model train epoch:90,loss:4.907279435428791e-05,training_time:0.5110354274511337
[[ 89.  58.]
 [ 12. 134.]]
step452
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7457958221435548}
Model train epoch:91,loss:4.814636122318916e-05,training_time:0.5188242569565773
[[ 89.  58.]
 [ 12. 134.]]
step456
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.747787594795227}
[[ 89.  58.]
 [ 12. 134.]]
step460
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7499294996261596}
Model train epoch:92,loss:4.774369954247959e-05,training_time:0.6101852357387543
[[ 89.  58.]
 [ 12. 134.]]
step464
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7521233797073363}
Model train epoch:93,loss:4.4702235754812136e-05,training_time:0.5496424213051796
[[ 89.  58.]
 [ 12. 134.]]
step468
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.754116940498352}
Model train epoch:94,loss:4.3295743307680826e-05,training_time:0.5213902518153191
[[ 89.  58.]
 [ 12. 134.]]
step472
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7559033155441284}
Model train epoch:95,loss:4.6680508239660413e-05,training_time:0.5385091379284859
[[ 89.  58.]
 [ 12. 134.]]
step476
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7583537578582764}
[[ 89.  58.]
 [ 12. 134.]]
step480
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7606454610824585}
Model train epoch:96,loss:4.25839658419136e-05,training_time:0.6271555349230766
[[ 89.  58.]
 [ 12. 134.]]
step484
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7630595922470094}
Model train epoch:97,loss:4.397690572659485e-05,training_time:0.5824044644832611
[[ 89.  58.]
 [ 12. 134.]]
step488
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7653457641601562}
Model train epoch:98,loss:4.1945361590478567e-05,training_time:0.5337545275688171
[[ 89.  58.]
 [ 12. 134.]]
step492
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.767425799369812}
Model train epoch:99,loss:4.082912637386471e-05,training_time:0.5606451630592346
[[ 89.  58.]
 [ 12. 134.]]
step496
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7691879987716674}
[[ 89.  58.]
 [ 12. 134.]]
step500
{'acc': 0.7610921501706485, 'f1': 0.7928994082840236, 'precision': 0.6979166666666666, 'recall': 0.9178082191780822, 'test_loss': 1.7709420442581176}
Model train epoch:100,loss:4.201695701340213e-05,training_time:0.6271485313773155
